{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-58bfc46e9411>\", line 7, in <module>\n",
      "    import skimage.io\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\__init__.py\", line 15, in <module>\n",
      "    reset_plugins()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 95, in reset_plugins\n",
      "    _load_preferred_plugins()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 75, in _load_preferred_plugins\n",
      "    _set_plugin(p_type, preferred_plugins['all'])\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 87, in _set_plugin\n",
      "    use_plugin(plugin, kind=plugin_type)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 258, in use_plugin\n",
      "    _load(name)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 302, in _load\n",
      "    fromlist=[modname])\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py\", line 4, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pycocotools\\coco.py:49: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"C:\\Users\\qianhuil\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "#image_dir\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "IMAGE_DIR_2 = os.path.join(ROOT_DIR, \"images_blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'mrcnn_mask_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_bbox_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(image_dir):\n",
    "    image = skimage.io.imread(image_dir)\n",
    "    # Create model object in inference mode.\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    # Load weights trained on MS-COCO\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "    \n",
    "\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    # person_list = [i for i, e in enumerate(r['class_ids']) if e ==1]    \n",
    "    test_image = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                class_names, r['scores'])    \n",
    "    #get person_class pixel out of r['masks']\n",
    "    person_list = [i for i, e in enumerate(r['class_ids']) if e ==1]    \n",
    "    pix_list = []\n",
    "    if len(person_list) != 0:\n",
    "        for i in person_list:\n",
    "            for row in range(r['rois'][i][0],r['rois'][i][2]+1):\n",
    "                for position in range(len(r['masks'][0])):\n",
    "                    if r['masks'][row][position][i] == True:\n",
    "                        pix_list.append([row,position])\n",
    "    return(pix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(pix_list,black_dir):\n",
    "    img = cv2.imread(black_dir)# black image with same size\n",
    "    print(len(img[0]))\n",
    "    new = img\n",
    "    for item in pix_list:\n",
    "    new[item[0]][item[1]] = [255,255,255]\n",
    "    new = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(new,127,255,0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "    # print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlurContours(image, contours, ksize, sigmaX, *args):\n",
    "    sigmaY = args[0] if len(args) > 0 else sigmaX\n",
    "    mask = np.zeros(image.shape[:2])\n",
    "    for i, contour in enumerate(contours):\n",
    "        cv2.drawContours(mask, contour, i, 255, -1)\n",
    "    blurred_image = cv2.GaussianBlur(image, (ksize, ksize), sigmaX, None, sigmaY)\n",
    "    result = np.copy(image)\n",
    "    alpha = mask/255.\n",
    "    result = alpha[:, :, None]*blurred_image + (1-alpha)[:, :, None]*result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":     \n",
    "    black_dir = 'D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\\black.png'\n",
    "    foldername= os.listdir(IMAGE_DIR)\n",
    "    j = 0\n",
    "    for subfolder in foldername: #subfolder,bottom_0\\\n",
    "        path = os.path.join(ROOT_DIR, subfolder)\n",
    "        for image_name in os.listdir(path): #image_name,01fb7befe10e876edb89e2935215f5603dd8f12d2b94363a37eae713.png\n",
    "            image_path = os.path.join(path,image_name)\n",
    "            image_set_list = segmentation(image_path)\n",
    "            image_con = contour(image_seg_list,black_dir)\n",
    "            image = cv2.imread(image_path)\n",
    "            for i in range(len(contours)):\n",
    "                contour_list = []\n",
    "                for j in contours[i]:\n",
    "                    contour_list.append(j)\n",
    "                \n",
    "                blur_image=BlurContours(image,[[np.array(contour_list)]],17,5)\n",
    "#                 cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "            new_image = blur_image[..., ::-1]\n",
    "            # print(new_image)\n",
    "            new_path = os.path.join(IMAGE_DIR_2,subfolder,image_name)\n",
    "            cv2.imwrite(new_path,new_image)\n",
    "            j = j+1\n",
    "            if j % 100 == 0:\n",
    "                    print(\"100 done\",j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\\images\\bottom_0\\01fb7befe10e876edb89e2935215f5603dd8f12d2b94363a37eae713.png\n"
     ]
    }
   ],
   "source": [
    "#for test code\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r\n",
    "a = list_files('D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\\images')\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\\images\\bottom_0\\01fb7befe10e876edb89e2935215f5603dd8f12d2b94363a37eae713.png\n"
     ]
    }
   ],
   "source": [
    "#for test code\n",
    "IMAGE_DIR = 'D:\\Summer\\crowdsourcing\\Mask_RCNN-master\\Mask_RCNN-master\\images'\n",
    "foldername= os.listdir (IMAGE_DIR)\n",
    "image_list = []\n",
    "for subfolder in foldername:\n",
    "    path = os.path.join(IMAGE_DIR, subfolder)\n",
    "    for image in os.listdir(path):\n",
    "        image_path = os.path.join(path,image)\n",
    "        image_list.append(image_path)\n",
    "print(image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test code\n",
    "for i in range(len(contours)):\n",
    "    contour_list = []\n",
    "    for j in contours[i]:\n",
    "        contour_list.append(j)\n",
    "    image=BlurContours(image,[[np.array(contour_list)]],17,5)\n",
    "    cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "new_image = image[..., ::-1]\n",
    "# print(new_image)\n",
    "cv2.imwrite('C:/Users/qianhuil/Desktop/2.jpg',new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
